"""
Enhanced Bloom Detection Processor for BloomWatch Kenya
Processes GEE exported data, detects bloom events, and prepares ML training data
Features:
- NDWI/NDVI threshold-based bloom area computation
- Historical data aggregation and time-series analysis
- ML training data preparation with binary labels
- Integration with enhanced Earth Engine pipeline
"""

import numpy as np
import pandas as pd
import logging
import os
import glob 
import csv
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Union
from scipy.signal import find_peaks
from pathlib import Path
import pickle

try:
    import rasterio
    RASTERIO_AVAILABLE = True
except ImportError:
    RASTERIO_AVAILABLE = False
    logger.warning("rasterio not available - using fallbacks")

try:
    from gee_data_loader import GEEDataLoader
    from ee_pipeline import EarthEnginePipeline
except ImportError:
    logger.warning("GEE modules not available - using fallbacks")
    GEEDataLoader = None
    EarthEnginePipeline = None

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Data directories
DATA_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'data'))
EXPORTS_DIR = os.path.join(DATA_DIR, 'exports')
LIVE_DATA_DIR = os.path.join(EXPORTS_DIR, 'live')
HISTORICAL_DIR = os.path.join(EXPORTS_DIR, 'historical')
MODELS_DIR = os.path.join(DATA_DIR, 'models')

# Create directories
for dir_path in [DATA_DIR, EXPORTS_DIR, LIVE_DATA_DIR, HISTORICAL_DIR, MODELS_DIR]:
    os.makedirs(dir_path, exist_ok=True)

# Bloom detection thresholds
NDWI_BLOOM_THRESHOLD = 0.3  # Water/bloom areas
NDVI_VEGETATION_THRESHOLD = 0.5  # Healthy vegetation
ARI_FLOWER_THRESHOLD = 0.15  # Flower pigments

class BloomProcessor:
    """Enhanced processor for satellite data, bloom detection, and ML data preparation"""
    
    def __init__(self, data_dir: str = None):
        """Initialize enhanced processor"""
        self.data_dir = data_dir or EXPORTS_DIR
        
        # Initialize data loader and pipeline
        if GEEDataLoader and EarthEnginePipeline:
            self.loader = GEEDataLoader(export_dir=self.data_dir)
            self.pipeline = EarthEnginePipeline()
        else:
            self.loader = None
            self.pipeline = None
            logger.warning("GEE modules not available - using fallback data")
        
        # Historical data cache
        self.historical_data = {}
        self.time_series_cache = {}
        
        logger.info(f"Enhanced Bloom Processor initialized: {self.data_dir}")
    
    def compute_bloom_areas(self, ndwi_threshold: float = NDWI_BLOOM_THRESHOLD, 
                           ndvi_threshold: float = NDVI_VEGETATION_THRESHOLD) -> Dict:
        """
        Compute bloom areas (sq km) using NDWI/NDVI thresholds
        
        Args:
            ndwi_threshold: NDWI threshold for bloom detection (default 0.3)
            ndvi_threshold: NDVI threshold for vegetation health (default 0.5)
        
        Returns:
            Dict with bloom area statistics
        """
        logger.info(f"Computing bloom areas with NDWI>{ndwi_threshold}, NDVI>{ndvi_threshold}")
        
        try:
            # Get live data from pipeline
            if self.pipeline:
                live_data = self.pipeline.fetch_live_data(days_back=3)
                bloom_area_result = self.pipeline.compute_bloom_area(ndwi_threshold, ndvi_threshold)
                
                if 'error' not in bloom_area_result:
                    return bloom_area_result
            
            # Fallback: use loaded data
            if self.loader:
                kenya_data = self.loader.load_kenya_data()
                
                # Simulate bloom area calculation with available data
                ndvi = kenya_data.get('ndvi')
                ndwi = kenya_data.get('ari', np.random.rand(*ndvi.shape) * 0.4)  # Use ARI as NDWI proxy
                
                if ndvi is not None:
                    # Create bloom mask
                    bloom_mask = (ndwi > ndwi_threshold) & (ndvi > ndvi_threshold)
                    
                    # Estimate area (assuming 1km pixel size for MODIS)
                    pixel_count = np.sum(bloom_mask)
                    area_km2 = pixel_count * 1.0  # 1 kmÂ² per pixel
                    
                    total_pixels = ndvi.size
                    bloom_percentage = (pixel_count / total_pixels) * 100
                    
                    return {
                        'bloom_area_km2': float(area_km2),
                        'total_region_km2': float(total_pixels),
                        'bloom_percentage': float(bloom_percentage),
                        'ndwi_threshold': ndwi_threshold,
                        'ndvi_threshold': ndvi_threshold,
                        'timestamp': datetime.now().isoformat(),
                        'method': 'Estimated from loaded data'
                    }
            
            # Generate synthetic bloom area for demo
            return self._generate_synthetic_bloom_area(ndwi_threshold, ndvi_threshold)
            
        except Exception as e:
            logger.error(f"Error computing bloom areas: {e}")
            return {'error': str(e)}
    
    def aggregate_historical_data(self, months_back: int = 12) -> Dict:
        """
        Aggregate historical data from /data/exports for time-series analysis
        
        Args:
            months_back: Number of months of historical data to aggregate
        
        Returns:
            Dict with aggregated time-series data
        """
        logger.info(f"Aggregating {months_back} months of historical data")
        
        try:
            # Look for CSV files in live data directory
            csv_files = glob.glob(os.path.join(LIVE_DATA_DIR, "*.csv"))
            
            if not csv_files:
                logger.warning("No historical CSV files found - generating synthetic data")
                return self._generate_synthetic_historical_data(months_back)
            
            # Read and aggregate CSV data
            all_data = []
            for csv_file in sorted(csv_files):
                try:
                    df = pd.read_csv(csv_file)
                    all_data.append(df)
                except Exception as e:
                    logger.warning(f"Error reading {csv_file}: {e}")
            
            if not all_data:
                return self._generate_synthetic_historical_data(months_back)
            
            # Combine all data
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # Create time series
            time_series = {
                'dates': combined_df.get('date', []).tolist(),
                'ndvi_values': combined_df.get('ndvi_mean', []).tolist(),
                'ndwi_values': combined_df.get('ndwi_mean', []).tolist(),
                'rainfall_values': combined_df.get('rainfall_total_mm', []).tolist(),
                'temperature_values': combined_df.get('temperature_mean_c', []).tolist(),
                'data_points': len(combined_df)
            }
            
            # Calculate statistics
            stats = {
                'ndvi_mean': float(combined_df.get('ndvi_mean', [0]).mean()) if 'ndvi_mean' in combined_df else 0,
                'ndvi_std': float(combined_df.get('ndvi_mean', [0]).std()) if 'ndvi_mean' in combined_df else 0,
                'rainfall_total': float(combined_df.get('rainfall_total_mm', [0]).sum()) if 'rainfall_total_mm' in combined_df else 0,
                'temperature_avg': float(combined_df.get('temperature_mean_c', [0]).mean()) if 'temperature_mean_c' in combined_df else 0
            }
            
            return {
                'time_series': time_series,
                'statistics': stats,
                'period_months': months_back,
                'data_source': 'Historical CSV files',
                'processed_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error aggregating historical data: {e}")
            return {'error': str(e)}
    
    def prepare_ml_training_data(self, include_weather: bool = True) -> Dict:
        """
        Prepare ML training data by merging bloom and climate data
        Creates binary labels (bloom/no bloom) based on thresholds
        
        Args:
            include_weather: Whether to include weather features
        
        Returns:
            Dict with training features and labels
        """
        logger.info("Preparing ML training data with binary bloom labels")
        
        try:
            # Get historical data
            historical = self.aggregate_historical_data()
            
            if 'error' in historical:
                logger.warning("Using synthetic data for ML training")
                return self._generate_synthetic_ml_data(include_weather)
            
            time_series = historical['time_series']
            
            # Prepare features
            features = []
            labels = []
            dates = []
            
            ndvi_values = time_series.get('ndvi_values', [])
            ndwi_values = time_series.get('ndwi_values', [])
            
            for i, (ndvi, ndwi) in enumerate(zip(ndvi_values, ndwi_values)):
                if ndvi > 0 and ndwi > 0:  # Valid data points
                    feature_row = [ndvi, ndwi]
                    
                    # Add weather features if requested
                    if include_weather:
                        rainfall = time_series.get('rainfall_values', [0] * len(ndvi_values))[i]
                        temp = time_series.get('temperature_values', [25] * len(ndvi_values))[i]
                        feature_row.extend([rainfall, temp])
                    
                    features.append(feature_row)
                    
                    # Create binary label based on thresholds
                    bloom_label = 1 if (ndwi > NDWI_BLOOM_THRESHOLD and ndvi > NDVI_VEGETATION_THRESHOLD) else 0
                    labels.append(bloom_label)
                    
                    # Add date if available
                    if i < len(time_series.get('dates', [])):
                        dates.append(time_series['dates'][i])
                    else:
                        dates.append(f"Day_{i}")
            
            # Convert to arrays
            X = np.array(features)
            y = np.array(labels)
            
            # Feature names
            feature_names = ['ndvi', 'ndwi']
            if include_weather:
                feature_names.extend(['rainfall_mm', 'temperature_c'])
            
            # Calculate class distribution
            bloom_count = np.sum(y == 1)
            no_bloom_count = np.sum(y == 0)
            
            return {
                'features': X,
                'labels': y,
                'dates': dates,
                'feature_names': feature_names,
                'n_samples': len(X),
                'n_features': X.shape[1] if len(X) > 0 else 0,
                'bloom_count': int(bloom_count),
                'no_bloom_count': int(no_bloom_count),
                'class_balance': float(bloom_count / len(y)) if len(y) > 0 else 0,
                'thresholds': {
                    'ndwi': NDWI_BLOOM_THRESHOLD,
                    'ndvi': NDVI_VEGETATION_THRESHOLD
                },
                'include_weather': include_weather,
                'prepared_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error preparing ML training data: {e}")
            return {'error': str(e)}
    
    def generate_time_series_data(self, data_type: str = 'ndvi', months: int = 12) -> Dict:
        """
        Generate time-series data for Streamlit visualizations
        
        Args:
            data_type: Type of data ('ndvi', 'ndwi', 'rainfall', 'temperature')
            months: Number of months to include
        
        Returns:
            Dict with time-series visualization data
        """
        logger.info(f"Generating {data_type} time-series for {months} months")
        
        try:
            # Get historical data
            historical = self.aggregate_historical_data(months)
            
            if 'error' in historical:
                return self._generate_synthetic_time_series(data_type, months)
            
            time_series = historical['time_series']
            
            # Extract requested data type
            if data_type == 'ndvi':
                values = time_series.get('ndvi_values', [])
                ylabel = 'NDVI'
                color = 'green'
            elif data_type == 'ndwi':
                values = time_series.get('ndwi_values', [])
                ylabel = 'NDWI'
                color = 'blue'
            elif data_type == 'rainfall':
                values = time_series.get('rainfall_values', [])
                ylabel = 'Rainfall (mm)'
                color = 'lightblue'
            elif data_type == 'temperature':
                values = time_series.get('temperature_values', [])
                ylabel = 'Temperature (Â°C)'
                color = 'red'
            else:
                logger.warning(f"Unknown data type: {data_type}")
                return {'error': f'Unknown data type: {data_type}'}
            
            dates = time_series.get('dates', [f"Day_{i}" for i in range(len(values))])
            
            return {
                'data_type': data_type,
                'dates': dates[:len(values)],
                'values': values,
                'ylabel': ylabel,
                'color': color,
                'n_points': len(values),
                'mean_value': float(np.mean(values)) if values else 0,
                'min_value': float(np.min(values)) if values else 0,
                'max_value': float(np.max(values)) if values else 0,
                'period_months': months,
                'generated_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error generating time-series data: {e}")
            return {'error': str(e)}
    
    def detect_bloom_events(self, region: str = 'kenya') -> Dict:
        """
        Enhanced bloom event detection with area computation
        
        Returns:
            Dict with bloom information including computed areas
        """
        logger.info(f"Detecting bloom events for region: {region}")
        
        try:
            # Compute bloom areas
            bloom_areas = self.compute_bloom_areas()
            
            # Get basic bloom detection from original method
            basic_results = self._detect_bloom_events_basic(region)
            
            # Combine results
            result = basic_results.copy()
            result.update({
                'bloom_area_km2': bloom_areas.get('bloom_area_km2', 0),
                'bloom_percentage': bloom_areas.get('bloom_percentage', 0),
                'computation_method': 'NDWI/NDVI thresholds'
            })
            
            return result
            
        except Exception as e:
            logger.error(f"Error detecting bloom events: {e}")
            return self._get_empty_result(region)
    
    def _detect_bloom_events_basic(self, region: str = 'kenya') -> Dict:
        """Basic bloom event detection (original method)"""
        try:
            if self.loader:
                kenya_data = self.loader.load_kenya_data()
            else:
                # Generate synthetic data
                kenya_data = self._generate_synthetic_kenya_data()
            
            result = {
                'data_source': kenya_data.get('source', 'Unknown'),
                'processed_at': datetime.now().isoformat(),
                'region': region
            }
            
            # Get NDVI and ARI
            ndvi = kenya_data.get('ndvi')
            ari = kenya_data.get('ari')
            
            if ndvi is None:
                logger.error("No NDVI data available")
                return self._get_empty_result(region)
            
            # Calculate NDVI statistics
            result['ndvi_mean'] = float(np.nanmean(ndvi))
            result['ndvi_std'] = float(np.nanstd(ndvi))
            result['ndvi_min'] = float(np.nanmin(ndvi))
            result['ndvi_max'] = float(np.nanmax(ndvi))
            
            # Health score (based on NDVI)
            result['health_score'] = self._calculate_health_score(ndvi)
            
            # Detect blooms from time series if available
            if 'time_series' in kenya_data:
                ts = kenya_data['time_series']
                bloom_months, scores = self._detect_from_time_series(ts, ari)
                result['bloom_months'] = bloom_months
                result['bloom_scores'] = scores.tolist()
                result['time_series_mean'] = [float(np.nanmean(ts[i])) for i in range(len(ts))]
            else:
                # Single-image bloom detection
                bloom_months, scores = self._detect_from_single_image(ndvi, ari)
                result['bloom_months'] = bloom_months
                result['bloom_scores'] = scores.tolist()
            
            # Generate bloom dates
            result['bloom_dates'] = self._get_bloom_dates(result['bloom_months'])
            
            # Identify bloom hotspots
            if ari is not None:
                result['bloom_hotspots'] = self._identify_hotspots(ari)
            
            logger.info(f"Detected {len(result['bloom_months'])} bloom events")
            
            return result
            
        except Exception as e:
            logger.error(f"Error in basic bloom detection: {e}")
            return self._get_empty_result(region)
    
    def _generate_synthetic_bloom_area(self, ndwi_threshold: float, ndvi_threshold: float) -> Dict:
        """Generate synthetic bloom area data for demo"""
        # Simulate realistic bloom area for Kenya region
        total_area_km2 = 12000  # Approximate area for central Kenya
        bloom_area_km2 = np.random.uniform(50, 500)  # Random bloom area
        bloom_percentage = (bloom_area_km2 / total_area_km2) * 100
        
        return {
            'bloom_area_km2': float(bloom_area_km2),
            'total_region_km2': float(total_area_km2),
            'bloom_percentage': float(bloom_percentage),
            'ndwi_threshold': ndwi_threshold,
            'ndvi_threshold': ndvi_threshold,
            'timestamp': datetime.now().isoformat(),
            'method': 'Synthetic demo data'
        }
    
    def _generate_synthetic_historical_data(self, months_back: int) -> Dict:
        """Generate synthetic historical data for demo"""
        dates = []
        ndvi_values = []
        ndwi_values = []
        rainfall_values = []
        temperature_values = []
        
        # Generate data for the last N months
        for i in range(months_back):
            date = (datetime.now() - timedelta(days=30*i)).strftime('%Y-%m-%d')
            dates.append(date)
            
            # Kenya seasonal patterns
            month = (datetime.now().month - i) % 12
            
            # NDVI (higher during rains)
            if 2 <= month <= 5 or 9 <= month <= 11:  # Rainy seasons
                ndvi = np.random.uniform(0.4, 0.8)
            else:
                ndvi = np.random.uniform(0.2, 0.5)
            ndvi_values.append(ndvi)
            
            # NDWI (correlated with blooms)
            ndwi = np.random.uniform(0.1, 0.6)
            ndwi_values.append(ndwi)
            
            # Rainfall (seasonal)
            if 2 <= month <= 5:  # Long rains
                rainfall = np.random.uniform(50, 200)
            elif 9 <= month <= 11:  # Short rains
                rainfall = np.random.uniform(30, 120)
            else:
                rainfall = np.random.uniform(0, 20)
            rainfall_values.append(rainfall)
            
            # Temperature (relatively stable)
            temperature = np.random.uniform(18, 28)
            temperature_values.append(temperature)
        
        time_series = {
            'dates': dates[::-1],  # Reverse to chronological order
            'ndvi_values': ndvi_values[::-1],
            'ndwi_values': ndwi_values[::-1],
            'rainfall_values': rainfall_values[::-1],
            'temperature_values': temperature_values[::-1],
            'data_points': months_back
        }
        
        stats = {
            'ndvi_mean': float(np.mean(ndvi_values)),
            'ndvi_std': float(np.std(ndvi_values)),
            'rainfall_total': float(np.sum(rainfall_values)),
            'temperature_avg': float(np.mean(temperature_values))
        }
        
        return {
            'time_series': time_series,
            'statistics': stats,
            'period_months': months_back,
            'data_source': 'Synthetic demo data',
            'processed_at': datetime.now().isoformat()
        }
    
    def _generate_synthetic_ml_data(self, include_weather: bool) -> Dict:
        """Generate synthetic ML training data"""
        n_samples = 100
        
        # Generate features
        ndvi = np.random.uniform(0.1, 0.9, n_samples)
        ndwi = np.random.uniform(0.0, 0.7, n_samples)
        
        features = [ndvi, ndwi]
        feature_names = ['ndvi', 'ndwi']
        
        if include_weather:
            rainfall = np.random.uniform(0, 150, n_samples)
            temperature = np.random.uniform(15, 30, n_samples)
            features.extend([rainfall, temperature])
            feature_names.extend(['rainfall_mm', 'temperature_c'])
        
        X = np.array(features).T
        
        # Generate labels based on thresholds
        y = ((ndwi > NDWI_BLOOM_THRESHOLD) & (ndvi > NDVI_VEGETATION_THRESHOLD)).astype(int)
        
        # Generate dates
        dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(n_samples)]
        
        bloom_count = np.sum(y == 1)
        no_bloom_count = np.sum(y == 0)
        
        return {
            'features': X,
            'labels': y,
            'dates': dates,
            'feature_names': feature_names,
            'n_samples': n_samples,
            'n_features': X.shape[1],
            'bloom_count': int(bloom_count),
            'no_bloom_count': int(no_bloom_count),
            'class_balance': float(bloom_count / n_samples),
            'thresholds': {
                'ndwi': NDWI_BLOOM_THRESHOLD,
                'ndvi': NDVI_VEGETATION_THRESHOLD
            },
            'include_weather': include_weather,
            'prepared_at': datetime.now().isoformat(),
            'data_source': 'Synthetic demo data'
        }
    
    def _generate_synthetic_time_series(self, data_type: str, months: int) -> Dict:
        """Generate synthetic time-series data"""
        dates = [(datetime.now() - timedelta(days=30*i)).strftime('%Y-%m-%d') for i in range(months)]
        dates.reverse()
        
        if data_type == 'ndvi':
            values = [np.random.uniform(0.2, 0.8) for _ in range(months)]
            ylabel = 'NDVI'
            color = 'green'
        elif data_type == 'ndwi':
            values = [np.random.uniform(0.1, 0.6) for _ in range(months)]
            ylabel = 'NDWI'
            color = 'blue'
        elif data_type == 'rainfall':
            values = [np.random.uniform(0, 150) for _ in range(months)]
            ylabel = 'Rainfall (mm)'
            color = 'lightblue'
        else:  # temperature
            values = [np.random.uniform(18, 28) for _ in range(months)]
            ylabel = 'Temperature (Â°C)'
            color = 'red'
        
        return {
            'data_type': data_type,
            'dates': dates,
            'values': values,
            'ylabel': ylabel,
            'color': color,
            'n_points': months,
            'mean_value': float(np.mean(values)),
            'min_value': float(np.min(values)),
            'max_value': float(np.max(values)),
            'period_months': months,
            'generated_at': datetime.now().isoformat(),
            'data_source': 'Synthetic demo data'
        }
    
    def _generate_synthetic_kenya_data(self) -> Dict:
        """Generate synthetic Kenya data (fallback)"""
        current_month = datetime.now().month
        
        # Generate Kenya-like NDVI patterns
        ndvi = np.random.rand(100, 100) * 0.6 + 0.2  # 0.2 to 0.8
        
        # Seasonal adjustment
        if 3 <= current_month <= 5:  # Long rains
            ndvi *= 1.4
        elif 10 <= current_month <= 12:  # Short rains
            ndvi *= 1.2
        else:
            ndvi *= 0.8
        
        # Generate ARI data
        ari = np.random.rand(100, 100) * 0.25
        
        return {
            'ndvi': ndvi,
            'ari': ari,
            'source': 'Synthetic Kenya data',
            'generated_at': datetime.now().isoformat()
        }
    
    def _calculate_health_score(self, ndvi: np.ndarray) -> float:
        """Calculate vegetation health score (0-100)"""
        # Normalize NDVI to health score
        mean_ndvi = np.nanmean(ndvi)
        
        # NDVI interpretation:
        # < 0.2: bare soil/low vegetation
        # 0.2-0.4: sparse vegetation
        # 0.4-0.6: moderate vegetation
        # 0.6-0.8: healthy vegetation
        # > 0.8: very healthy/dense vegetation
        
        if mean_ndvi < 0.2:
            score = mean_ndvi * 100  # 0-20
        elif mean_ndvi < 0.4:
            score = 20 + (mean_ndvi - 0.2) * 150  # 20-50
        elif mean_ndvi < 0.6:
            score = 50 + (mean_ndvi - 0.4) * 125  # 50-75
        else:
            score = 75 + (mean_ndvi - 0.6) * 62.5  # 75-100
        
        return min(100.0, max(0.0, float(score)))
    
    def _detect_from_time_series(self, ts: np.ndarray, ari: np.ndarray = None) -> Tuple[List[int], np.ndarray]:
        """
        Detect bloom events from NDVI time series
        
        Args:
            ts: Time series array (time, height, width)
            ari: Anthocyanin Reflectance Index (optional)
        
        Returns:
            bloom_months: List of month indices with blooms
            scores: Confidence scores for each month
        """
        # Calculate mean NDVI for each time step
        ndvi_mean = np.array([np.nanmean(ts[i]) for i in range(len(ts))])
        
        # Find peaks in NDVI (high vegetation)
        peaks, properties = find_peaks(
            ndvi_mean,
            prominence=0.05,  # Minimum prominence
            width=1  # Minimum width
        )
        
        # Score based on NDVI values
        scores = np.zeros(len(ts))
        
        for peak in peaks:
            # Score based on NDVI value and prominence
            ndvi_score = min(1.0, ndvi_mean[peak] / 0.8)  # Normalize to 0.8
            
            # Bonus for ARI if available
            ari_bonus = 0.0
            if ari is not None:
                ari_mean = np.nanmean(ari)
                ari_bonus = min(0.2, ari_mean)  # Up to 0.2 bonus
            
            scores[peak] = min(1.0, ndvi_score + ari_bonus)
        
        # Filter low scores
        bloom_months = [int(peak) for peak in peaks if scores[peak] > 0.4]
        
        # Add Kenya-specific bloom season adjustments
        bloom_months = self._adjust_for_kenya_seasons(bloom_months, scores)
        
        return bloom_months, scores
    
    def _detect_from_single_image(self, ndvi: np.ndarray, ari: np.ndarray = None) -> Tuple[List[int], np.ndarray]:
        """Detect likely bloom months from single NDVI image"""
        # Estimate bloom months based on current NDVI and Kenya crop calendar
        current_month = datetime.now().month
        mean_ndvi = np.nanmean(ndvi)
        
        scores = np.zeros(12)
        bloom_months = []
        
        # Kenya bloom seasons:
        # Long rains: March-May (3-5)
        # Short rains: October-December (10-12)
        
        if mean_ndvi > 0.5:  # Healthy vegetation
            # Current season
            if 2 <= current_month <= 5:  # Long rains
                bloom_months = [3, 4]
                scores[3] = 0.8
                scores[4] = 0.7
            elif 9 <= current_month <= 12:  # Short rains
                bloom_months = [10, 11]
                scores[10] = 0.7
                scores[11] = 0.6
            else:  # Dry season - predict next season
                if current_month < 3:
                    bloom_months = [3, 4]
                    scores[3] = 0.6
                    scores[4] = 0.5
                else:
                    bloom_months = [10, 11]
                    scores[10] = 0.6
                    scores[11] = 0.5
        
        # Boost score if ARI is high
        if ari is not None:
            ari_mean = np.nanmean(ari)
            if ari_mean > 0.15:
                for month in bloom_months:
                    scores[month] += 0.2
        
        return bloom_months, scores
    
    def _adjust_for_kenya_seasons(self, bloom_months: List[int], scores: np.ndarray) -> List[int]:
        """Adjust bloom detections based on Kenya crop calendar"""
        # Kenya's main bloom periods
        long_rains = [2, 3, 4]  # March-May (0-indexed)
        short_rains = [9, 10, 11]  # Oct-Dec
        
        adjusted = []
        
        for month in bloom_months:
            # Keep if in known bloom season
            if month in long_rains or month in short_rains:
                adjusted.append(month)
            # Otherwise, check if score is very high
            elif scores[month] > 0.7:
                adjusted.append(month)
        
        return adjusted
    
    def _get_bloom_dates(self, bloom_months: List[int]) -> List[str]:
        """Convert month indices to actual dates"""
        current_year = datetime.now().year
        month_names = [
            'January', 'February', 'March', 'April', 'May', 'June',
            'July', 'August', 'September', 'October', 'November', 'December'
        ]
        
        bloom_dates = []
        for month_idx in bloom_months:
            # Adjust for 0-indexed months
            month_num = month_idx + 1 if month_idx < 12 else 1
            year = current_year
            
            # If month is in past, assume next year
            if month_num < datetime.now().month:
                year += 1
            
            bloom_dates.append(f"{month_names[month_idx]} {year}")
        
        return bloom_dates
    
    def _identify_hotspots(self, ari: np.ndarray, threshold: float = 0.2) -> List[Dict]:
        """Identify bloom hotspots from ARI data"""
        # Find regions with high ARI (flower pigments)
        hotspots = []
        
        # Simple threshold-based detection
        high_ari = ari > threshold
        
        if np.any(high_ari):
            # Count hotspot pixels
            num_hotspots = int(np.sum(high_ari))
            max_ari = float(np.nanmax(ari))
            
            hotspots.append({
                'intensity': max_ari,
                'area_pixels': num_hotspots,
                'location': 'Central Kenya',  # Would be more specific with actual coords
                'confidence': min(1.0, max_ari / 0.3)
            })
        
        return hotspots
    
    def _get_empty_result(self, region: str) -> Dict:
        """Return empty result structure"""
        return {
            'data_source': 'None',
            'processed_at': datetime.now().isoformat(),
            'region': region,
            'bloom_months': [],
            'bloom_scores': [],
            'bloom_dates': [],
            'bloom_area_km2': 0,
            'bloom_percentage': 0,
            'error': 'No data available'
        }
    
    def get_region_summary(self, region: str = 'kenya') -> Dict:
        """Get enhanced summary statistics for a region"""
        bloom_data = self.detect_bloom_events(region)
        
        summary = {
            'region': region,
            'data_source': bloom_data.get('data_source'),
            'health_score': bloom_data.get('health_score', 0),
            'num_bloom_events': len(bloom_data.get('bloom_months', [])),
            'next_bloom': bloom_data['bloom_dates'][0] if bloom_data.get('bloom_dates') else 'Unknown',
            'bloom_area_km2': bloom_data.get('bloom_area_km2', 0),
            'bloom_percentage': bloom_data.get('bloom_percentage', 0),
            'updated_at': bloom_data.get('processed_at')
        }
        
        return summary


# Enhanced Testing
if __name__ == "__main__":
    print("ğŸŒ¸ Enhanced Bloom Processor Test")
    print("=" * 60)
    
    processor = BloomProcessor()
    
    # Test 1: Bloom area computation
    print("\nğŸ§® Testing bloom area computation...")
    bloom_areas = processor.compute_bloom_areas()
    
    if 'error' not in bloom_areas:
        print(f"âœ… Bloom area: {bloom_areas.get('bloom_area_km2', 0):.2f} kmÂ²")
        print(f"ğŸ“Š Coverage: {bloom_areas.get('bloom_percentage', 0):.2f}% of region")
        print(f"ğŸ¯ Method: {bloom_areas.get('method', 'Unknown')}")
    else:
        print(f"âŒ Error: {bloom_areas['error']}")
    
    # Test 2: Historical data aggregation
    print("\nğŸ“ˆ Testing historical data aggregation...")
    historical = processor.aggregate_historical_data(months_back=6)
    
    if 'error' not in historical:
        print(f"âœ… Data points: {historical['time_series']['data_points']}")
        print(f"ğŸ“Š Data source: {historical['data_source']}")
        print(f"ğŸ“ˆ NDVI mean: {historical['statistics']['ndvi_mean']:.3f}")
        print(f"ğŸŒ§ï¸ Total rainfall: {historical['statistics']['rainfall_total']:.1f} mm")
    else:
        print(f"âŒ Error: {historical['error']}")
    
    # Test 3: ML training data preparation
    print("\nğŸ¤– Testing ML training data preparation...")
    ml_data = processor.prepare_ml_training_data(include_weather=True)
    
    if 'error' not in ml_data:
        print(f"âœ… Samples: {ml_data['n_samples']}")
        print(f"ğŸ”¢ Features: {ml_data['n_features']} ({', '.join(ml_data['feature_names'])})")
        print(f"ğŸŒ¸ Bloom samples: {ml_data['bloom_count']}")
        print(f"ğŸš« No-bloom samples: {ml_data['no_bloom_count']}")
        print(f"âš–ï¸ Class balance: {ml_data['class_balance']:.2%}")
    else:
        print(f"âŒ Error: {ml_data['error']}")
    
    # Test 4: Time-series data generation
    print("\nğŸ“Š Testing time-series data generation...")
    for data_type in ['ndvi', 'ndwi', 'rainfall', 'temperature']:
        ts_data = processor.generate_time_series_data(data_type, months=6)
        
        if 'error' not in ts_data:
            print(f"âœ… {data_type.upper()}: {ts_data['n_points']} points, "
                  f"mean={ts_data['mean_value']:.2f}")
        else:
            print(f"âŒ {data_type.upper()} error: {ts_data['error']}")
    
    # Test 5: Enhanced bloom detection
    print("\nğŸ” Testing enhanced bloom detection...")
    results = processor.detect_bloom_events('kenya')
    
    print(f"\nğŸ“Š Data Source: {results['data_source']}")
    print(f"ğŸŒ± Health Score: {results.get('health_score', 0):.1f}/100")
    print(f"ğŸŒ¸ Bloom Events: {len(results['bloom_months'])}")
    print(f"ğŸ—ºï¸ Bloom Area: {results.get('bloom_area_km2', 0):.2f} kmÂ²")
    print(f"ğŸ“ˆ Coverage: {results.get('bloom_percentage', 0):.2f}%")
    
    if results['bloom_dates']:
        print("\nğŸ“… Predicted Bloom Dates:")
        for i, date in enumerate(results['bloom_dates']):
            if i < len(results['bloom_scores']):
                score = results['bloom_scores'][i]
                print(f"  â€¢ {date} (confidence: {score:.0%})")
    
    if results.get('ndvi_mean'):
        print(f"\nğŸ“ˆ NDVI Statistics:")
        print(f"  Mean: {results['ndvi_mean']:.3f}")
        print(f"  Range: {results['ndvi_min']:.3f} - {results['ndvi_max']:.3f}")
    
    # Enhanced region summary
    print("\nğŸ“‹ Enhanced Region Summary:")
    summary = processor.get_region_summary('kenya')
    for key, value in summary.items():
        print(f"  {key}: {value}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ Enhanced Bloom Processor test complete!")
    print("\nNew Features Added:")
    print("  âœ… NDWI/NDVI threshold-based bloom area computation")
    print("  âœ… Historical data aggregation and time-series analysis")
    print("  âœ… ML training data preparation with binary labels")
    print("  âœ… Time-series visualization data generation")
    print("  âœ… Integration with enhanced Earth Engine pipeline")





